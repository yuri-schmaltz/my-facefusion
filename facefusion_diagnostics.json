{
    "environment": {
        "timestamp": "2026-02-02T18:40:16.945478",
        "facefusion_version": "3.5.2",
        "python_version": "3.12.9 (tags/v3.12.9:fdb8142, Feb  4 2025, 15:27:58) [MSC v.1942 64 bit (AMD64)]",
        "os": "Windows",
        "os_release": "11",
        "os_version": "10.0.26100",
        "architecture": "AMD64",
        "processor": "AMD64 Family 25 Model 120 Stepping 0, AuthenticAMD",
        "executable": "C:\\Users\\u60897\\Documents\\my-facefusion\\.venv\\Scripts\\python.exe",
        "working_directory": "C:\\Users\\u60897\\Documents\\my-facefusion",
        "torch_available": false,
        "onnxruntime_version": "1.23.2",
        "onnxruntime_providers": [
            "TensorrtExecutionProvider",
            "CUDAExecutionProvider",
            "CPUExecutionProvider"
        ],
        "ffmpeg_available": true
    },
    "logs": [
        {
            "filename": "facefusion.log",
            "content": [
                "    detect_vision_frame = prepare_detect_frame(vision_frame, 'nsfw_1')\n",
                "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
                "  File \"/home/yurix/Documentos/my-facefusion/facefusion/content_analyser.py\", line 257, in prepare_detect_frame\n",
                "    detect_vision_frame = fit_contain_frame(temp_vision_frame, model_size)\n",
                "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
                "  File \"/home/yurix/Documentos/my-facefusion/facefusion/vision.py\", line 259, in fit_contain_frame\n",
                "    height, width = vision_frame.shape[:2]\n",
                "                    ^^^^^^^^^^^^^^^^^^\n",
                "AttributeError: 'NoneType' object has no attribute 'shape'\n",
                "\n",
                "2026-02-01 13:01:13,148 - facefusion - INFO - [FACEFUSION.CORE] processing step 1 of 1\n",
                "2026-02-01 13:01:18,783 - facefusion - INFO - [FACEFUSION.IMAGE_TO_IMAGE] copying image with a resolution of 426x226\n",
                "2026-02-01 13:01:18,900 - facefusion - INFO - [FACEFUSION.CORE] processing\n",
                "2026-02-01 13:01:29,098 - facefusion - INFO - [FACEFUSION.IMAGE_TO_IMAGE] finalizing image with a resolution of 426x226\n",
                "2026-02-01 13:01:29,214 - facefusion - INFO - [FACEFUSION.IMAGE_TO_IMAGE] processing to image succeeded in 12.17 seconds\n",
                "2026-02-01 13:01:30,918 - facefusion - INFO - [FACEFUSION.CORE] processing step 1 of 1\n",
                "2026-02-01 13:01:35,980 - facefusion - INFO - [FACEFUSION.IMAGE_TO_VIDEO] extracting frames with a resolution of 426x226 and 25.0 frames per second\n",
                "2026-02-01 13:01:46,224 - facefusion - INFO - [FACEFUSION.IMAGE_TO_VIDEO] merging video with a resolution of 426x226 and 25.0 frames per second\n",
                "2026-02-01 13:01:46,447 - facefusion - ERROR - [FACEFUSION.FFMPEG] Stream map '1:a:0' matches no streams.\n",
                "2026-02-01 13:01:46,447 - facefusion - ERROR - [FACEFUSION.FFMPEG] To ignore this, add a trailing '?' to the map.\n",
                "2026-02-01 13:01:46,448 - facefusion - ERROR - [FACEFUSION.FFMPEG] Failed to set value '1:a:0' for option 'map': Invalid argument\n",
                "2026-02-01 13:01:46,448 - facefusion - ERROR - [FACEFUSION.FFMPEG] Error parsing options for output file /tmp/facefusion-test-outputs/test-age-face-to-video.mp4.\n",
                "2026-02-01 13:01:46,448 - facefusion - ERROR - [FACEFUSION.FFMPEG] Error opening output files: Invalid argument\n",
                "2026-02-01 13:01:46,450 - facefusion - WARNING - [FACEFUSION.IMAGE_TO_VIDEO] restoring audio skipped\n",
                "2026-02-01 13:01:46,451 - facefusion - INFO - [FACEFUSION.IMAGE_TO_VIDEO] processing to video succeeded in 12.19 seconds\n",
                "2026-02-01 13:01:48,142 - facefusion - INFO - [FACEFUSION.CORE] processing step 1 of 1\n",
                "2026-02-01 13:01:51,571 - facefusion - INFO - [FACEFUSION.IMAGE_TO_IMAGE] copying image with a resolution of 426x226\n",
                "2026-02-01 13:01:51,687 - facefusion - INFO - [FACEFUSION.CORE] processing\n",
                "2026-02-01 13:01:52,280 - facefusion - INFO - [FACEFUSION.IMAGE_TO_IMAGE] finalizing image with a resolution of 426x226\n",
                "2026-02-01 13:01:52,395 - facefusion - INFO - [FACEFUSION.IMAGE_TO_IMAGE] processing to image succeeded in 2.61 seconds\n",
                "2026-02-01 13:01:53,912 - facefusion - INFO - [FACEFUSION.CORE] processing step 1 of 1\n",
                "2026-02-01 13:01:57,249 - facefusion - INFO - [FACEFUSION.IMAGE_TO_VIDEO] extracting frames with a resolution of 426x226 and 25.0 frames per second\n",
                "2026-02-01 13:01:57,923 - facefusion - INFO - [FACEFUSION.IMAGE_TO_VIDEO] merging video with a resolution of 426x226 and 25.0 frames per second\n",
                "2026-02-01 13:01:58,149 - facefusion - ERROR - [FACEFUSION.FFMPEG] Stream map '1:a:0' matches no streams.\n",
                "2026-02-01 13:01:58,150 - facefusion - ERROR - [FACEFUSION.FFMPEG] To ignore this, add a trailing '?' to the map.\n",
                "2026-02-01 13:01:58,150 - facefusion - ERROR - [FACEFUSION.FFMPEG] Failed to set value '1:a:0' for option 'map': Invalid argument\n",
                "2026-02-01 13:01:58,150 - facefusion - ERROR - [FACEFUSION.FFMPEG] Error parsing options for output file /tmp/facefusion-test-outputs/test-background-blur-video.mp4.\n",
                "2026-02-01 13:01:58,151 - facefusion - ERROR - [FACEFUSION.FFMPEG] Error opening output files: Invalid argument\n",
                "2026-02-01 13:01:58,156 - facefusion - WARNING - [FACEFUSION.IMAGE_TO_VIDEO] restoring audio skipped\n",
                "2026-02-01 13:01:58,157 - facefusion - INFO - [FACEFUSION.IMAGE_TO_VIDEO] processing to video succeeded in 2.58 seconds\n",
                "2026-02-01 13:02:00,238 - facefusion - INFO - [FACEFUSION.CORE] processing step 1 of 1\n",
                "2026-02-01 13:02:05,495 - facefusion - INFO - [FACEFUSION.IMAGE_TO_IMAGE] copying image with a resolution of 426x226\n",
                "2026-02-01 13:02:05,618 - facefusion - INFO - [FACEFUSION.CORE] processing\n",
                "2026-02-01 13:02:26,294 - facefusion - INFO - [FACEFUSION.IMAGE_TO_IMAGE] finalizing image with a resolution of 426x226\n",
                "2026-02-01 13:02:26,411 - facefusion - INFO - [FACEFUSION.IMAGE_TO_IMAGE] processing to image succeeded in 22.79 seconds\n",
                "2026-02-01 13:02:28,010 - facefusion - INFO - [FACEFUSION.CORE] processing step 1 of 1\n",
                "2026-02-01 13:02:32,709 - facefusion - INFO - [FACEFUSION.IMAGE_TO_VIDEO] extracting frames with a resolution of 426x226 and 25.0 frames per second\n",
                "2026-02-02 18:39:53,527 - facefusion - INFO - [FACEFUSION.DIAGNOSTICS] Creating diagnostic bundle: facefusion_diagnostics.json\n",
                "2026-02-02 18:39:53,661 - facefusion - INFO - [FACEFUSION.DIAGNOSTICS] Diagnostic bundle created successfully at facefusion_diagnostics.json\n",
                "2026-02-02 18:40:16,945 - facefusion - INFO - [FACEFUSION.DIAGNOSTICS] Creating diagnostic bundle: facefusion_diagnostics.json\n"
            ]
        },
        {
            "filename": "facefusion.json",
            "content": [
                "{\"asctime\": \"2026-02-01 13:00:34,701\", \"name\": \"facefusion\", \"levelname\": \"INFO\", \"message\": \"[FACEFUSION.CORE] processing step 1 of 1\", \"module\": \"logger\", \"lineno\": 49}\n",
                "{\"asctime\": \"2026-02-01 13:00:38,232\", \"name\": \"facefusion.orchestrator.runner\", \"levelname\": \"ERROR\", \"message\": \"Job job-20260201-130034-9768dc66 failed: Traceback (most recent call last):\\n  File \\\"/home/yurix/Documentos/my-facefusion/facefusion/orchestrator/runner.py\\\", line 136, in run\\n    success = process_step_orchestrator(job_id, 0, len(self.job.steps), config)\\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/home/yurix/Documentos/my-facefusion/facefusion/core.py\\\", line 389, in process_step_orchestrator\\n    error_code = conditional_process()\\n                 ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/home/yurix/Documentos/my-facefusion/facefusion/core.py\\\", line 404, in conditional_process\\n    image_to_video.process(start_time)\\n  File \\\"/home/yurix/Documentos/my-facefusion/facefusion/workflows/image_to_video.py\\\", line 36, in process\\n    error_code = task() # type:ignore[operator]\\n                 ^^^^^^\\n  File \\\"/home/yurix/Documentos/my-facefusion/facefusion/workflows/image_to_video.py\\\", line 49, in setup\\n    if analyse_video(state_manager.get_item('target_path'), trim_frame_start, trim_frame_end):\\n       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/home/yurix/Documentos/my-facefusion/facefusion/content_analyser.py\\\", line 187, in analyse_video\\n    if future.result():\\n       ^^^^^^^^^^^^^^^\\n  File \\\"/usr/lib/python3.12/concurrent/futures/_base.py\\\", line 449, in result\\n    return self.__get_result()\\n           ^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/lib/python3.12/concurrent/futures/_base.py\\\", line 401, in __get_result\\n    raise self._exception\\n  File \\\"/usr/lib/python3.12/concurrent/futures/thread.py\\\", line 58, in run\\n    result = self.fn(*self.args, **self.kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/home/yurix/Documentos/my-facefusion/facefusion/content_analyser.py\\\", line 204, in analyse_video_frame\\n    return analyse_frame(vision_frame)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/home/yurix/Documentos/my-facefusion/facefusion/content_analyser.py\\\", line 157, in analyse_frame\\n    return detect_nsfw(vision_frame)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/home/yurix/Documentos/my-facefusion/facefusion/content_analyser.py\\\", line 208, in detect_nsfw\\n    is_nsfw_1 = detect_with_nsfw_1(vision_frame)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/home/yurix/Documentos/my-facefusion/facefusion/content_analyser.py\\\", line 216, in detect_with_nsfw_1\\n    detect_vision_frame = prepare_detect_frame(vision_frame, 'nsfw_1')\\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/home/yurix/Documentos/my-facefusion/facefusion/content_analyser.py\\\", line 257, in prepare_detect_frame\\n    detect_vision_frame = fit_contain_frame(temp_vision_frame, model_size)\\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/home/yurix/Documentos/my-facefusion/facefusion/vision.py\\\", line 259, in fit_contain_frame\\n    height, width = vision_frame.shape[:2]\\n                    ^^^^^^^^^^^^^^^^^^\\nAttributeError: 'NoneType' object has no attribute 'shape'\\n\", \"module\": \"runner\", \"lineno\": 163}\n",
                "{\"asctime\": \"2026-02-01 13:00:39,911\", \"name\": \"facefusion\", \"levelname\": \"INFO\", \"message\": \"[FACEFUSION.CORE] processing step 1 of 1\", \"module\": \"logger\", \"lineno\": 49}\n",
                "{\"asctime\": \"2026-02-01 13:00:44,805\", \"name\": \"facefusion\", \"levelname\": \"INFO\", \"message\": \"[FACEFUSION.IMAGE_TO_VIDEO] extracting frames with a resolution of 640x480 and 29.97002997002997 frames per second\", \"module\": \"logger\", \"lineno\": 49}\n",
                "{\"asctime\": \"2026-02-01 13:00:56,350\", \"name\": \"facefusion\", \"levelname\": \"INFO\", \"message\": \"[FACEFUSION.IMAGE_TO_VIDEO] merging video with a resolution of 640x480 and 29.97002997002997 frames per second\", \"module\": \"logger\", \"lineno\": 49}\n",
                "{\"asctime\": \"2026-02-01 13:00:56,660\", \"name\": \"facefusion\", \"levelname\": \"INFO\", \"message\": \"[FACEFUSION.IMAGE_TO_VIDEO] processing to video succeeded in 15.08 seconds\", \"module\": \"logger\", \"lineno\": 49}\n",
                "{\"asctime\": \"2026-02-01 13:00:58,150\", \"name\": \"facefusion\", \"levelname\": \"INFO\", \"message\": \"[FACEFUSION.CORE] processing step 1 of 1\", \"module\": \"logger\", \"lineno\": 49}\n",
                "{\"asctime\": \"2026-02-01 13:01:01,646\", \"name\": \"facefusion.orchestrator.runner\", \"levelname\": \"ERROR\", \"message\": \"Job job-20260201-130058-4c2ff0da failed: Traceback (most recent call last):\\n  File \\\"/home/yurix/Documentos/my-facefusion/facefusion/orchestrator/runner.py\\\", line 136, in run\\n    success = process_step_orchestrator(job_id, 0, len(self.job.steps), config)\\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/home/yurix/Documentos/my-facefusion/facefusion/core.py\\\", line 389, in process_step_orchestrator\\n    error_code = conditional_process()\\n                 ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/home/yurix/Documentos/my-facefusion/facefusion/core.py\\\", line 404, in conditional_process\\n    image_to_video.process(start_time)\\n  File \\\"/home/yurix/Documentos/my-facefusion/facefusion/workflows/image_to_video.py\\\", line 36, in process\\n    error_code = task() # type:ignore[operator]\\n                 ^^^^^^\\n  File \\\"/home/yurix/Documentos/my-facefusion/facefusion/workflows/image_to_video.py\\\", line 49, in setup\\n    if analyse_video(state_manager.get_item('target_path'), trim_frame_start, trim_frame_end):\\n       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/home/yurix/Documentos/my-facefusion/facefusion/content_analyser.py\\\", line 187, in analyse_video\\n    if future.result():\\n       ^^^^^^^^^^^^^^^\\n  File \\\"/usr/lib/python3.12/concurrent/futures/_base.py\\\", line 449, in result\\n    return self.__get_result()\\n           ^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/lib/python3.12/concurrent/futures/_base.py\\\", line 401, in __get_result\\n    raise self._exception\\n  File \\\"/usr/lib/python3.12/concurrent/futures/thread.py\\\", line 58, in run\\n    result = self.fn(*self.args, **self.kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/home/yurix/Documentos/my-facefusion/facefusion/content_analyser.py\\\", line 204, in analyse_video_frame\\n    return analyse_frame(vision_frame)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/home/yurix/Documentos/my-facefusion/facefusion/content_analyser.py\\\", line 157, in analyse_frame\\n    return detect_nsfw(vision_frame)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/home/yurix/Documentos/my-facefusion/facefusion/content_analyser.py\\\", line 208, in detect_nsfw\\n    is_nsfw_1 = detect_with_nsfw_1(vision_frame)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/home/yurix/Documentos/my-facefusion/facefusion/content_analyser.py\\\", line 216, in detect_with_nsfw_1\\n    detect_vision_frame = prepare_detect_frame(vision_frame, 'nsfw_1')\\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/home/yurix/Documentos/my-facefusion/facefusion/content_analyser.py\\\", line 257, in prepare_detect_frame\\n    detect_vision_frame = fit_contain_frame(temp_vision_frame, model_size)\\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/home/yurix/Documentos/my-facefusion/facefusion/vision.py\\\", line 259, in fit_contain_frame\\n    height, width = vision_frame.shape[:2]\\n                    ^^^^^^^^^^^^^^^^^^\\nAttributeError: 'NoneType' object has no attribute 'shape'\\n\", \"module\": \"runner\", \"lineno\": 163}\n",
                "{\"asctime\": \"2026-02-01 13:01:03,259\", \"name\": \"facefusion\", \"levelname\": \"INFO\", \"message\": \"[FACEFUSION.CORE] processing step 1 of 1\", \"module\": \"logger\", \"lineno\": 49}\n",
                "{\"asctime\": \"2026-02-01 13:01:07,011\", \"name\": \"facefusion.orchestrator.runner\", \"levelname\": \"ERROR\", \"message\": \"Job job-20260201-130103-1f7f19e8 failed: Traceback (most recent call last):\\n  File \\\"/home/yurix/Documentos/my-facefusion/facefusion/orchestrator/runner.py\\\", line 136, in run\\n    success = process_step_orchestrator(job_id, 0, len(self.job.steps), config)\\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/home/yurix/Documentos/my-facefusion/facefusion/core.py\\\", line 389, in process_step_orchestrator\\n    error_code = conditional_process()\\n                 ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/home/yurix/Documentos/my-facefusion/facefusion/core.py\\\", line 404, in conditional_process\\n    image_to_video.process(start_time)\\n  File \\\"/home/yurix/Documentos/my-facefusion/facefusion/workflows/image_to_video.py\\\", line 36, in process\\n    error_code = task() # type:ignore[operator]\\n                 ^^^^^^\\n  File \\\"/home/yurix/Documentos/my-facefusion/facefusion/workflows/image_to_video.py\\\", line 49, in setup\\n    if analyse_video(state_manager.get_item('target_path'), trim_frame_start, trim_frame_end):\\n       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/home/yurix/Documentos/my-facefusion/facefusion/content_analyser.py\\\", line 187, in analyse_video\\n    if future.result():\\n       ^^^^^^^^^^^^^^^\\n  File \\\"/usr/lib/python3.12/concurrent/futures/_base.py\\\", line 449, in result\\n    return self.__get_result()\\n           ^^^^^^^^^^^^^^^^^^^\\n  File \\\"/usr/lib/python3.12/concurrent/futures/_base.py\\\", line 401, in __get_result\\n    raise self._exception\\n  File \\\"/usr/lib/python3.12/concurrent/futures/thread.py\\\", line 58, in run\\n    result = self.fn(*self.args, **self.kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/home/yurix/Documentos/my-facefusion/facefusion/content_analyser.py\\\", line 204, in analyse_video_frame\\n    return analyse_frame(vision_frame)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/home/yurix/Documentos/my-facefusion/facefusion/content_analyser.py\\\", line 157, in analyse_frame\\n    return detect_nsfw(vision_frame)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/home/yurix/Documentos/my-facefusion/facefusion/content_analyser.py\\\", line 208, in detect_nsfw\\n    is_nsfw_1 = detect_with_nsfw_1(vision_frame)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/home/yurix/Documentos/my-facefusion/facefusion/content_analyser.py\\\", line 216, in detect_with_nsfw_1\\n    detect_vision_frame = prepare_detect_frame(vision_frame, 'nsfw_1')\\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/home/yurix/Documentos/my-facefusion/facefusion/content_analyser.py\\\", line 257, in prepare_detect_frame\\n    detect_vision_frame = fit_contain_frame(temp_vision_frame, model_size)\\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"/home/yurix/Documentos/my-facefusion/facefusion/vision.py\\\", line 259, in fit_contain_frame\\n    height, width = vision_frame.shape[:2]\\n                    ^^^^^^^^^^^^^^^^^^\\nAttributeError: 'NoneType' object has no attribute 'shape'\\n\", \"module\": \"runner\", \"lineno\": 163}\n",
                "{\"asctime\": \"2026-02-01 13:01:13,148\", \"name\": \"facefusion\", \"levelname\": \"INFO\", \"message\": \"[FACEFUSION.CORE] processing step 1 of 1\", \"module\": \"logger\", \"lineno\": 49}\n",
                "{\"asctime\": \"2026-02-01 13:01:18,783\", \"name\": \"facefusion\", \"levelname\": \"INFO\", \"message\": \"[FACEFUSION.IMAGE_TO_IMAGE] copying image with a resolution of 426x226\", \"module\": \"logger\", \"lineno\": 49}\n",
                "{\"asctime\": \"2026-02-01 13:01:18,900\", \"name\": \"facefusion\", \"levelname\": \"INFO\", \"message\": \"[FACEFUSION.CORE] processing\", \"module\": \"logger\", \"lineno\": 49}\n",
                "{\"asctime\": \"2026-02-01 13:01:29,098\", \"name\": \"facefusion\", \"levelname\": \"INFO\", \"message\": \"[FACEFUSION.IMAGE_TO_IMAGE] finalizing image with a resolution of 426x226\", \"module\": \"logger\", \"lineno\": 49}\n",
                "{\"asctime\": \"2026-02-01 13:01:29,214\", \"name\": \"facefusion\", \"levelname\": \"INFO\", \"message\": \"[FACEFUSION.IMAGE_TO_IMAGE] processing to image succeeded in 12.17 seconds\", \"module\": \"logger\", \"lineno\": 49}\n",
                "{\"asctime\": \"2026-02-01 13:01:30,918\", \"name\": \"facefusion\", \"levelname\": \"INFO\", \"message\": \"[FACEFUSION.CORE] processing step 1 of 1\", \"module\": \"logger\", \"lineno\": 49}\n",
                "{\"asctime\": \"2026-02-01 13:01:35,980\", \"name\": \"facefusion\", \"levelname\": \"INFO\", \"message\": \"[FACEFUSION.IMAGE_TO_VIDEO] extracting frames with a resolution of 426x226 and 25.0 frames per second\", \"module\": \"logger\", \"lineno\": 49}\n",
                "{\"asctime\": \"2026-02-01 13:01:46,224\", \"name\": \"facefusion\", \"levelname\": \"INFO\", \"message\": \"[FACEFUSION.IMAGE_TO_VIDEO] merging video with a resolution of 426x226 and 25.0 frames per second\", \"module\": \"logger\", \"lineno\": 49}\n",
                "{\"asctime\": \"2026-02-01 13:01:46,447\", \"name\": \"facefusion\", \"levelname\": \"ERROR\", \"message\": \"[FACEFUSION.FFMPEG] Stream map '1:a:0' matches no streams.\", \"module\": \"logger\", \"lineno\": 57}\n",
                "{\"asctime\": \"2026-02-01 13:01:46,447\", \"name\": \"facefusion\", \"levelname\": \"ERROR\", \"message\": \"[FACEFUSION.FFMPEG] To ignore this, add a trailing '?' to the map.\", \"module\": \"logger\", \"lineno\": 57}\n",
                "{\"asctime\": \"2026-02-01 13:01:46,448\", \"name\": \"facefusion\", \"levelname\": \"ERROR\", \"message\": \"[FACEFUSION.FFMPEG] Failed to set value '1:a:0' for option 'map': Invalid argument\", \"module\": \"logger\", \"lineno\": 57}\n",
                "{\"asctime\": \"2026-02-01 13:01:46,448\", \"name\": \"facefusion\", \"levelname\": \"ERROR\", \"message\": \"[FACEFUSION.FFMPEG] Error parsing options for output file /tmp/facefusion-test-outputs/test-age-face-to-video.mp4.\", \"module\": \"logger\", \"lineno\": 57}\n",
                "{\"asctime\": \"2026-02-01 13:01:46,448\", \"name\": \"facefusion\", \"levelname\": \"ERROR\", \"message\": \"[FACEFUSION.FFMPEG] Error opening output files: Invalid argument\", \"module\": \"logger\", \"lineno\": 57}\n",
                "{\"asctime\": \"2026-02-01 13:01:46,450\", \"name\": \"facefusion\", \"levelname\": \"WARNING\", \"message\": \"[FACEFUSION.IMAGE_TO_VIDEO] restoring audio skipped\", \"module\": \"logger\", \"lineno\": 53}\n",
                "{\"asctime\": \"2026-02-01 13:01:46,451\", \"name\": \"facefusion\", \"levelname\": \"INFO\", \"message\": \"[FACEFUSION.IMAGE_TO_VIDEO] processing to video succeeded in 12.19 seconds\", \"module\": \"logger\", \"lineno\": 49}\n",
                "{\"asctime\": \"2026-02-01 13:01:48,142\", \"name\": \"facefusion\", \"levelname\": \"INFO\", \"message\": \"[FACEFUSION.CORE] processing step 1 of 1\", \"module\": \"logger\", \"lineno\": 49}\n",
                "{\"asctime\": \"2026-02-01 13:01:51,571\", \"name\": \"facefusion\", \"levelname\": \"INFO\", \"message\": \"[FACEFUSION.IMAGE_TO_IMAGE] copying image with a resolution of 426x226\", \"module\": \"logger\", \"lineno\": 49}\n",
                "{\"asctime\": \"2026-02-01 13:01:51,687\", \"name\": \"facefusion\", \"levelname\": \"INFO\", \"message\": \"[FACEFUSION.CORE] processing\", \"module\": \"logger\", \"lineno\": 49}\n",
                "{\"asctime\": \"2026-02-01 13:01:52,280\", \"name\": \"facefusion\", \"levelname\": \"INFO\", \"message\": \"[FACEFUSION.IMAGE_TO_IMAGE] finalizing image with a resolution of 426x226\", \"module\": \"logger\", \"lineno\": 49}\n",
                "{\"asctime\": \"2026-02-01 13:01:52,395\", \"name\": \"facefusion\", \"levelname\": \"INFO\", \"message\": \"[FACEFUSION.IMAGE_TO_IMAGE] processing to image succeeded in 2.61 seconds\", \"module\": \"logger\", \"lineno\": 49}\n",
                "{\"asctime\": \"2026-02-01 13:01:53,912\", \"name\": \"facefusion\", \"levelname\": \"INFO\", \"message\": \"[FACEFUSION.CORE] processing step 1 of 1\", \"module\": \"logger\", \"lineno\": 49}\n",
                "{\"asctime\": \"2026-02-01 13:01:57,249\", \"name\": \"facefusion\", \"levelname\": \"INFO\", \"message\": \"[FACEFUSION.IMAGE_TO_VIDEO] extracting frames with a resolution of 426x226 and 25.0 frames per second\", \"module\": \"logger\", \"lineno\": 49}\n",
                "{\"asctime\": \"2026-02-01 13:01:57,923\", \"name\": \"facefusion\", \"levelname\": \"INFO\", \"message\": \"[FACEFUSION.IMAGE_TO_VIDEO] merging video with a resolution of 426x226 and 25.0 frames per second\", \"module\": \"logger\", \"lineno\": 49}\n",
                "{\"asctime\": \"2026-02-01 13:01:58,149\", \"name\": \"facefusion\", \"levelname\": \"ERROR\", \"message\": \"[FACEFUSION.FFMPEG] Stream map '1:a:0' matches no streams.\", \"module\": \"logger\", \"lineno\": 57}\n",
                "{\"asctime\": \"2026-02-01 13:01:58,150\", \"name\": \"facefusion\", \"levelname\": \"ERROR\", \"message\": \"[FACEFUSION.FFMPEG] To ignore this, add a trailing '?' to the map.\", \"module\": \"logger\", \"lineno\": 57}\n",
                "{\"asctime\": \"2026-02-01 13:01:58,150\", \"name\": \"facefusion\", \"levelname\": \"ERROR\", \"message\": \"[FACEFUSION.FFMPEG] Failed to set value '1:a:0' for option 'map': Invalid argument\", \"module\": \"logger\", \"lineno\": 57}\n",
                "{\"asctime\": \"2026-02-01 13:01:58,150\", \"name\": \"facefusion\", \"levelname\": \"ERROR\", \"message\": \"[FACEFUSION.FFMPEG] Error parsing options for output file /tmp/facefusion-test-outputs/test-background-blur-video.mp4.\", \"module\": \"logger\", \"lineno\": 57}\n",
                "{\"asctime\": \"2026-02-01 13:01:58,151\", \"name\": \"facefusion\", \"levelname\": \"ERROR\", \"message\": \"[FACEFUSION.FFMPEG] Error opening output files: Invalid argument\", \"module\": \"logger\", \"lineno\": 57}\n",
                "{\"asctime\": \"2026-02-01 13:01:58,156\", \"name\": \"facefusion\", \"levelname\": \"WARNING\", \"message\": \"[FACEFUSION.IMAGE_TO_VIDEO] restoring audio skipped\", \"module\": \"logger\", \"lineno\": 53}\n",
                "{\"asctime\": \"2026-02-01 13:01:58,157\", \"name\": \"facefusion\", \"levelname\": \"INFO\", \"message\": \"[FACEFUSION.IMAGE_TO_VIDEO] processing to video succeeded in 2.58 seconds\", \"module\": \"logger\", \"lineno\": 49}\n",
                "{\"asctime\": \"2026-02-01 13:02:00,238\", \"name\": \"facefusion\", \"levelname\": \"INFO\", \"message\": \"[FACEFUSION.CORE] processing step 1 of 1\", \"module\": \"logger\", \"lineno\": 49}\n",
                "{\"asctime\": \"2026-02-01 13:02:05,495\", \"name\": \"facefusion\", \"levelname\": \"INFO\", \"message\": \"[FACEFUSION.IMAGE_TO_IMAGE] copying image with a resolution of 426x226\", \"module\": \"logger\", \"lineno\": 49}\n",
                "{\"asctime\": \"2026-02-01 13:02:05,618\", \"name\": \"facefusion\", \"levelname\": \"INFO\", \"message\": \"[FACEFUSION.CORE] processing\", \"module\": \"logger\", \"lineno\": 49}\n",
                "{\"asctime\": \"2026-02-01 13:02:26,294\", \"name\": \"facefusion\", \"levelname\": \"INFO\", \"message\": \"[FACEFUSION.IMAGE_TO_IMAGE] finalizing image with a resolution of 426x226\", \"module\": \"logger\", \"lineno\": 49}\n",
                "{\"asctime\": \"2026-02-01 13:02:26,411\", \"name\": \"facefusion\", \"levelname\": \"INFO\", \"message\": \"[FACEFUSION.IMAGE_TO_IMAGE] processing to image succeeded in 22.79 seconds\", \"module\": \"logger\", \"lineno\": 49}\n",
                "{\"asctime\": \"2026-02-01 13:02:28,010\", \"name\": \"facefusion\", \"levelname\": \"INFO\", \"message\": \"[FACEFUSION.CORE] processing step 1 of 1\", \"module\": \"logger\", \"lineno\": 49}\n",
                "{\"asctime\": \"2026-02-01 13:02:32,709\", \"name\": \"facefusion\", \"levelname\": \"INFO\", \"message\": \"[FACEFUSION.IMAGE_TO_VIDEO] extracting frames with a resolution of 426x226 and 25.0 frames per second\", \"module\": \"logger\", \"lineno\": 49}\n",
                "{\"asctime\": \"2026-02-02 18:39:53,527\", \"name\": \"facefusion\", \"levelname\": \"INFO\", \"message\": \"[FACEFUSION.DIAGNOSTICS] Creating diagnostic bundle: facefusion_diagnostics.json\", \"module\": \"logger\", \"lineno\": 49}\n",
                "{\"asctime\": \"2026-02-02 18:39:53,661\", \"name\": \"facefusion\", \"levelname\": \"INFO\", \"message\": \"[FACEFUSION.DIAGNOSTICS] Diagnostic bundle created successfully at facefusion_diagnostics.json\", \"module\": \"logger\", \"lineno\": 49}\n",
                "{\"asctime\": \"2026-02-02 18:40:16,945\", \"name\": \"facefusion\", \"levelname\": \"INFO\", \"message\": \"[FACEFUSION.DIAGNOSTICS] Creating diagnostic bundle: facefusion_diagnostics.json\", \"module\": \"logger\", \"lineno\": 49}\n"
            ]
        }
    ],
    "orchestrator": {
        "total_jobs": 0,
        "by_status": {
            "drafted": 0,
            "queued": 0,
            "running": 0,
            "completed": 0,
            "failed": 0,
            "canceled": 0
        }
    }
}